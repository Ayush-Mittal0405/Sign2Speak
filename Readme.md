# ğŸ–ï¸ Sign Language Detection with Multi-Language Voice Output

A real-time **Sign Language Detection System** built using **YOLO (Ultralytics)** that recognizes hand gestures through a webcam and converts them into **spoken audio output** in multiple regional languages.

This project is designed to improve **accessibility and communication** for speech-impaired and hearing-impaired individuals.

---

## ğŸš€ Features

- ğŸ¯ Real-time sign language detection using webcam
- ğŸ”Š Voice output for detected signs
- ğŸŒ Multi-language support  
  - English  
  - Hindi  
  - Gujarati
- ğŸ” Instant language switching  
  - `SPACE` key (PC / Laptop)  
  - Physical button (Raspberry Pi GPIO)
- â±ï¸ Audio cooldown to avoid repeated speech
- ğŸ’» Works on **PC and Raspberry Pi**

---

## ğŸ§  How It Works

1. Webcam captures live video
2. YOLO model detects hand gestures
3. Detected class label is identified
4. Corresponding audio file is played
5. User can switch output language instantly

---

## ğŸ› ï¸ Tech Stack Used

### Programming Language
- Python ğŸ

### Machine Learning & Computer Vision
- YOLO (Ultralytics)
- OpenCV

### Audio Handling
- Pygame
  
---

## ğŸ“¦ Required Libraries

```txt
ultralytics
pygame
opencv-python
numpy

